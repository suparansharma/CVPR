# -*- coding: utf-8 -*-
"""MNIST_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qs-81Nol99aOV0YwmD37T7yIKLvlFOF-
"""

import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras import layers

tf.test.gpu_device_name()

(X_train, y_train) , (X_test, y_test) = keras.datasets.mnist.load_data()

print(X_train.shape, y_train.shape)
print(X_test.shape, y_test.shape)

X_train_flattened = X_train / 255
X_test_flattened = X_test / 255

X_train = X_train.reshape(-1,28,28,1)
X_test = X_test.reshape(-1,28,28,1)
X_train_flattened = X_train_flattened.reshape(-1,28,28,1)
X_test_flattened = X_test_flattened.reshape(-1,28,28,1)

X_train[0].shape

model = keras.Sequential([
    ## input layer
    keras.Input(shape=(28,28,1)),
    
    ## hidden layers
    layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),
    layers.MaxPooling2D(pool_size=(2,2)),
    layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),
    layers.MaxPooling2D(pool_size=(2,2)),
    layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),
    layers.MaxPooling2D(pool_size=(2,2)),
    
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    
    ## output layer
    layers.Dense(10, activation='softmax')
])
model.summary()

model.compile(
    optimizer='adam', 
    loss='sparse_categorical_crossentropy', 
    metrics=['accuracy']
)

"""<h1> First we fit the unflattened data into our model and check the accuracy </h1>"""

h = model.fit(X_train, y_train, epochs=5)

model.evaluate(X_test, y_test)

"""<b> We get 98% accuracy on our test dataset without normalizing our data </b>"""

y_predicted = model.predict(X_test)

y_predicted_labels = [np.argmax(i) for i in y_predicted]

cm = tf.math.confusion_matrix(labels=y_test,predictions=y_predicted_labels)
cm

"""<b> Now we summarize our models performance</b>"""

import seaborn as sn
plt.figure(figsize = (10,7))
sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Truth')

"""**All predictions**"""

import random
ROWS = 5
COLS = 20

random_indices = random.sample(range(X_test.shape[0]), ROWS*COLS)
sample_images = X_test[random_indices, :]
sample_labels = y_test[random_indices]
y_predicted = model.predict(sample_images)

i = 0

plt.figure(figsize=(20,5))
for r in range(ROWS):
    for c in range(COLS):
        plt.subplot(ROWS, COLS, i+1)
        plt.imshow(sample_images[i].reshape(28,28), cmap=plt.cm.gray)
        plt.xticks([])
        plt.yticks([])
        prediction = np.argmax(y_predicted[i]) 
        confidence = y_predicted[i][prediction]
        if sample_labels[i] == prediction:
            plt.xlabel(f"{prediction} ({confidence: .2f})", color='b')
        else:
            plt.xlabel(f"{prediction} ({confidence: .2f})", color='r')
        plt.ylabel(sample_labels[i], color='g')
        i += 1
        
plt.tight_layout()
plt.show()

"""<h1> Now we fit the normalized dataset into out model </h1>"""

h = model.fit(X_train_flattened, y_train, epochs=5)

model.evaluate(X_test_flattened, y_test)

"""**Surprisingly we got a slightly less test accuracy after normalizing the data!**"""

y_predicted = model.predict(X_test_flattened)

y_predicted_labels = [np.argmax(i) for i in y_predicted]

cm2 = tf.math.confusion_matrix(labels=y_test,predictions=y_predicted_labels)

"""**let's visualize the performance for this one**"""

plt.figure(figsize = (10,7))
sn.heatmap(cm2, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Truth')

"""**All predictions**"""

ROWS = 5
COLS = 20

random_indices = random.sample(range(X_test_flattened.shape[0]), ROWS*COLS)
sample_images = X_test_flattened[random_indices, :]
sample_labels = y_test[random_indices]
y_predicted = model.predict(sample_images)

i = 0

plt.figure(figsize=(20,5))
for r in range(ROWS):
    for c in range(COLS):
        plt.subplot(ROWS, COLS, i+1)
        plt.imshow(sample_images[i].reshape(28,28), cmap=plt.cm.gray)
        plt.xticks([])
        plt.yticks([])
        prediction = np.argmax(y_predicted[i]) 
        confidence = y_predicted[i][prediction]
        if sample_labels[i] == prediction:
            plt.xlabel(f"{prediction} ({confidence: .2f})", color='b')
        else:
            plt.xlabel(f"{prediction} ({confidence: .2f})", color='r')
        plt.ylabel(sample_labels[i], color='g')
        i += 1
        
plt.tight_layout()
plt.show()

"""<b>Now we use different Optimizers called SGD and RMSprop """

model.compile(
    optimizer='SGD', 
    loss='sparse_categorical_crossentropy', 
    metrics=['accuracy']
)

h = model.fit(X_train_flattened, y_train, epochs=5)

model.evaluate(X_test_flattened, y_test)

model.compile(
    optimizer='RMSprop', 
    loss='sparse_categorical_crossentropy', 
    metrics=['accuracy']
)

h = model.fit(X_train_flattened, y_train, epochs=5)

model.evaluate(X_test_flattened, y_test)

"""<b>conclusion : </b> Both of them got slightly better test accuracy than adam, SGD got 98.78% accuracy and RMSprop got 98.63% accuracy where adam has 98.25% accuracy. And considering no of epochs, SGD and RMSprop got a very good accuracy within the first epoch. """